{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from parameters_x import *\n",
    "\n",
    "\n",
    "def rev_ema(x):\n",
    "    x = list(x)\n",
    "    x.reverse()\n",
    "    df = pd.Series(x)\n",
    "    df_ewm = df.ewm(alpha=0.98).mean()\n",
    "    df_ewm = list(df_ewm)\n",
    "    df_ewm.reverse()\n",
    "    df_ewm = pd.Series(df_ewm)\n",
    "    return df_ewm\n",
    "\n",
    "\n",
    "# def select_500(name_time, data, time_str):\n",
    "#     name = name_time[(name_time[\"year\"] == time_str) & (name_time[\"month\"] == 3)][\"stock_name\"]\n",
    "#     time = name_time[(name_time[\"year\"] == time_str) & (name_time[\"half\"] == 0)][\"time\"]\n",
    "#     df1 = data[data.stock_name.isin(name) & data.time.isin(time)].copy()\n",
    "#     # print(df1)\n",
    "#     name = name_time[(name_time[\"year\"] == time_str) & (name_time[\"month\"] == 9)][\"stock_name\"]\n",
    "#     time = name_time[(name_time[\"year\"] == time_str) & (name_time[\"half\"] == 1)][\"time\"]\n",
    "#     df2 = data[data.stock_name.isin(name) & data.time.isin(time)].copy()\n",
    "#     # print(df2)\n",
    "#     df = pd.concat([df1, df2])\n",
    "#     return df\n",
    "\n",
    "\n",
    "def hist_count(l1, l2, nums):\n",
    "    df = pd.DataFrame({\"a\": l1, \"b\": l2})\n",
    "    df['c'] = 0\n",
    "    df = df.groupby(['a', 'b']).count().reset_index()\n",
    "    w = np.zeros([nums, nums])\n",
    "    for _, row in df.iterrows():\n",
    "        w[int(row.a), int(row.b)] = row.c\n",
    "    return w\n",
    "\n",
    "\n",
    "def simple_re_wheeled(data, f_to_use, bst, version='long'):\n",
    "    re_list = []\n",
    "    rank_pre = []\n",
    "    rank_label = []\n",
    "    turn = []\n",
    "    last_stock_name = []\n",
    "    nums_return = []\n",
    "    nums_p_return = []\n",
    "    market_return_list = []\n",
    "    limit_tag_list = []\n",
    "    time_list = []\n",
    "    time_series = list(sorted(set(list(data['date_time']))))\n",
    "    for day in time_series:\n",
    "        d_te = data[data['date_time'] == day].copy()[f_to_use]\n",
    "        all_te = data[data['date_time'] == day].copy()\n",
    "        market_return = [all_te[\"return\"].mean()]*len(all_te)\n",
    "        X_test = xgb.DMatrix(d_te)\n",
    "        # print(bst.best_ntree_limit)\n",
    "        preds = bst.predict(X_test, ntree_limit=bst.best_ntree_limit)\n",
    "        stock_name = np.array(all_te['unique_symbol'])\n",
    "        if version == 'long':\n",
    "            test_bs, test_select_tag = make_decision_long(preds, rightbound)\n",
    "        test_select_buffer_tag = make_decision_buffer(preds, stock_name, last_stock_name, rightbound, bufferbound)\n",
    "#         暂时不考虑降低换手\n",
    "#         test_select_tag = test_select_buffer_tag\n",
    "        return_list = np.array(all_te['return'])\n",
    "        stock_list = list(np.array(all_te['unique_symbol'])[test_select_tag])\n",
    "        # re = (return_list[test_select_tag] * test_bs)\n",
    "        re = return_list[test_select_tag]\n",
    "        re_list.append(re.mean())\n",
    "        print(\"###############################################\")\n",
    "        print(stock_list)\n",
    "        print(re.mean(), day)\n",
    "        print(re)\n",
    "        rank_pre = rank_pre + list(pd.qcut(pd.Series(preds).rank(method='first'), 10, labels=False))\n",
    "        rank_label = rank_label + list(all_te['rank_label'])\n",
    "        nums_p_return = nums_p_return + list(preds)\n",
    "        nums_return = nums_return + list(return_list)\n",
    "        time_list = time_list + list(all_te[\"date_time\"])\n",
    "        market_return_list = market_return_list + market_return\n",
    "        limit_tag_list = limit_tag_list + list(all_te[\"limit_tag\"])\n",
    "        turn.append(stock_list)\n",
    "        last_stock_name = stock_list\n",
    "        # print(len(stock_list))\n",
    "    return re_list, rank_pre, rank_label, turn, nums_p_return, nums_return, market_return_list, limit_tag_list,time_list\n",
    "\n",
    "\n",
    "def make_decision_long(preds, rightbound):\n",
    "    bs = []\n",
    "    select_tag = []\n",
    "    for i in range(len(preds)):\n",
    "        if preds[i] >= np.percentile(preds, rightbound):\n",
    "            bs.append(1)\n",
    "            select_tag.append(True)\n",
    "        else:\n",
    "            select_tag.append(False)\n",
    "    bs = np.array(bs)\n",
    "    select_tag = np.array(select_tag)\n",
    "    return bs, select_tag\n",
    "\n",
    "\n",
    "def make_decision_buffer(preds, stock_name, last_stock_name, rightbound, bufferbound):\n",
    "\n",
    "    select_tag = []\n",
    "    bs = []\n",
    "    select_tag_buffer = []\n",
    "    stock_name = np.array(stock_name)\n",
    "    preds = np.array(preds)\n",
    "    for i in range(len(preds)):\n",
    "        if preds[i] >= np.percentile(preds, rightbound):\n",
    "            bs.append(1)\n",
    "            select_tag.append(True)\n",
    "        else:\n",
    "            select_tag.append(False)\n",
    "        if preds[i] >= np.percentile(preds, bufferbound):\n",
    "            select_tag_buffer.append(True)\n",
    "        else:\n",
    "            select_tag_buffer.append(False)\n",
    "    s_rightbound = set(stock_name[np.array(select_tag)])\n",
    "    s_bufferbound = set(stock_name[np.array(select_tag_buffer)])\n",
    "    # print(len(s_rightbound), len(s_bufferbound))\n",
    "    # print(\"last_stock_name:\", len(last_stock_name))\n",
    "    s1 = s_rightbound & set(last_stock_name)\n",
    "    s2 = (set(last_stock_name) - s1) & s_bufferbound\n",
    "    # print(\"s1 len:\", len(s1),\"s2 len:\", len(s2))\n",
    "    s12 = s1 | s2\n",
    "    s3len = len(s_rightbound) - len(s12)\n",
    "    # print('s3len', s3len)\n",
    "    s3candidate_stock_name = list(s_rightbound - s12)\n",
    "    # print('s3candidate_stock_name', len(s3candidate_stock_name))\n",
    "    stock_name = list(stock_name)\n",
    "    s3candidate_name_index = [[i, preds[stock_name.index(i)]] for i in s3candidate_stock_name]\n",
    "    # print(s3candidate_name_index)\n",
    "    s3 = np.array(sorted(s3candidate_name_index, reverse=True, key=lambda x: x[1])[:s3len])\n",
    "    # print(s3)\n",
    "    if s3 != []:\n",
    "        s3 = s3[:, 0]\n",
    "    # print(\"s3 len:\", len(s3))\n",
    "    s = list(s1)+list(s2)+list(s3)\n",
    "    select_tag_buffer = [stock_name.index(i) for i in s]\n",
    "    select_tag_buffer = np.array(select_tag_buffer)\n",
    "    return select_tag_buffer\n",
    "\n",
    "\n",
    "def train_op(X_train, y_train, params, num_rounds, X_v, y_v, early):\n",
    "    d_train = xgb.DMatrix(X_train, y_train)\n",
    "    dtest = xgb.DMatrix(X_v, y_v)\n",
    "    eval_set = [(d_train, 'train'), (dtest, 'eval')]\n",
    "    bst = xgb.train(params, d_train, num_boost_round=num_rounds, evals=eval_set, early_stopping_rounds=early)\n",
    "    return bst\n",
    "\n",
    "\n",
    "def f_importance(bst, f_to_use):\n",
    "    importance_dic= {}\n",
    "    for f in f_to_use:\n",
    "        importance_dic[f] = []\n",
    "    sum = 0\n",
    "    for feature_name in bst.get_fscore():\n",
    "        sum = sum + bst.get_fscore()[feature_name]\n",
    "    for feature_name, feature_socre in bst.get_fscore().items():\n",
    "        importance_dic[feature_name].append(feature_socre/sum)\n",
    "    # xgb.plot_importance(bst)\n",
    "    # plt.show()\n",
    "    return importance_dic\n",
    "\n",
    "\n",
    "def f_importance_bar(importance_dic):\n",
    "    top = 20\n",
    "    name = []\n",
    "    importance_mean = []\n",
    "    importance_mean_dic = {}\n",
    "    for feature, importance in importance_dic.items():\n",
    "        name.append(feature)\n",
    "        temp = np.array(importance).mean()\n",
    "        if np.isnan(temp):\n",
    "            importance_mean.append(0)\n",
    "        else:\n",
    "            importance_mean.append(temp)\n",
    "        importance_mean_dic[feature] = importance_mean[-1]\n",
    "    name = np.array(name)\n",
    "    sorted_imp = [[importance_mean[i], i] for i in range(len(importance_mean))]\n",
    "    sorted_imp = sorted(sorted_imp, key=lambda student: student[0], reverse=True)\n",
    "    sorted_imp = np.array(sorted_imp[:top])\n",
    "    top_index = sorted_imp[:, 1]\n",
    "    top_index = [int(i) for i in top_index]\n",
    "\n",
    "    sns.barplot(y=name[top_index], x=sorted_imp[:, 0], orient='h', alpha=0.8, color='red')\n",
    "    plt.ylabel('Factor', fontsize=10)\n",
    "    plt.xlabel('Importance', fontsize=10)\n",
    "    plt.xticks(rotation='horizontal')\n",
    "    plt.yticks(fontsize=17)\n",
    "\n",
    "\n",
    "def prepare_data(data, time, col):\n",
    "    data = data[col]\n",
    "    data = data[data.time.isin(time)].copy()\n",
    "    return data\n",
    "\n",
    "\n",
    "def acc_return(re_list, turnover=None):\n",
    "    if turnover == None:\n",
    "        turnover = len(re_list)*[0]\n",
    "    net_worth = [1]\n",
    "    for i in range(len(re_list)):\n",
    "        r = re_list[i]\n",
    "        net_worth.append(net_worth[-1]*(1 + r - 0.002*turnover[i]))\n",
    "    return net_worth\n",
    "\n",
    "\n",
    "def add_return(re_list, turnover=None):\n",
    "    if turnover == None:\n",
    "        turnover = len(re_list)*[0]\n",
    "    net_worth = [1]\n",
    "    for i in range(len(re_list)):\n",
    "        r = re_list[i]\n",
    "        net_worth.append(net_worth[-1] + r - 0.002*turnover[i])\n",
    "    return net_worth\n",
    "\n",
    "\n",
    "def nshift(df, gb_col, col, n):\n",
    "    for i in range(1, n):\n",
    "        gb = df.groupby([gb_col])[col]\n",
    "        df[col + str(i)] = gb.transform(lambda x: x.shift(i))\n",
    "    return df\n",
    "\n",
    "\n",
    "def norm_pcol(df, col, adjust_col, n):\n",
    "    for i in range(1, n):\n",
    "        df[col + str(i)] = (df[col + str(i)] - df[adjust_col] + df[adjust_col + str(i)])/df['close']\n",
    "    return df\n",
    "\n",
    "\n",
    "def norm_vcol(df, col, n):\n",
    "    for i in range(1, n):\n",
    "        df[col + str(i)] = df[col + str(i)]/df[col]\n",
    "    return df\n",
    "\n",
    "\n",
    "def select_year(y, time_series):\n",
    "    return [i for i in time_series if i[:4] == y]\n",
    "\n",
    "\n",
    "def max_decline_acc(r_path):\n",
    "    d = [[0, 0]]\n",
    "    max_tag = [r_path[0], 0]\n",
    "    for i in range(1, len(r_path)):\n",
    "        r = r_path[i]\n",
    "        if max_tag[0] < r:\n",
    "            max_tag[0] = r\n",
    "            max_tag[1] = i\n",
    "            d.append([0, i])\n",
    "        elif max_tag[0] >= r:\n",
    "            d.append([(r - max_tag[0])/max_tag[0], max_tag[1]])\n",
    "    return np.array(d)\n",
    "\n",
    "\n",
    "def max_decline_add(r_path):\n",
    "    d = [[0, 0]]\n",
    "    max_tag = [r_path[0], 0]\n",
    "    for i in range(1, len(r_path)):\n",
    "        r = r_path[i]\n",
    "        if max_tag[0] < r:\n",
    "            max_tag[0] = r\n",
    "            max_tag[1] = i\n",
    "            d.append([0, i])\n",
    "        elif max_tag[0] >= r:\n",
    "            d.append([r - max_tag[0], max_tag[1]])\n",
    "    return np.array(d)\n",
    "\n",
    "\n",
    "def turnover_analysis(all_te_time, buy_v, sell_v, turn):\n",
    "    turnover = [1]\n",
    "    pd_time = []\n",
    "    for i in range(len(all_te_time)):\n",
    "        pd_time = pd_time + len(turn[i])*[all_te_time[i]]\n",
    "    for i in range(1, len(turn)):\n",
    "        turnover.append(len(list(set(turn[i]) - set(turn[i-1])))/len(turn[i]))\n",
    "    # sns.distplot(turnover, kde=True, rug=True)\n",
    "    print(\"turnover:\", np.mean(np.array(turnover)))\n",
    "    print(\"turnover:\", len(turnover))\n",
    "    df = pd.DataFrame({'time': pd_time, 'buy_v': buy_v, 'sell_v': sell_v})\n",
    "    df_turn = pd.DataFrame({'time': all_te_time, 'turnover': turnover})\n",
    "    df_all = pd.merge(df, df_turn, how='outer')\n",
    "    df_all['year'] = df_all[\"time\"].apply(lambda x: x[:4])\n",
    "    # plt.savefig(\".\\\\pic\\\\turnover_analysis.png\")\n",
    "    # plt.show()\n",
    "    return turnover\n",
    "\n",
    "\n",
    "def pnl_analysis(all_te_time, market_return, r, importance_dic, pre, real_re, turnover, type):\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    r = np.array(r)\n",
    "    market_return = np.array(market_return)\n",
    "    if type == 'add':\n",
    "        w = add_return(r, turnover)\n",
    "        ls_r = r - market_return\n",
    "        ls_r_pnl = add_return(ls_r, turnover)\n",
    "        market_pnl = add_return(market_return)\n",
    "        decline = max_decline_add(w)\n",
    "        ls_decline = max_decline_add(ls_r_pnl)\n",
    "    else:\n",
    "        w = acc_return(r, turnover)\n",
    "        ls_r = r - market_return\n",
    "        ls_r_pnl = acc_return(ls_r, turnover)\n",
    "        market_pnl = acc_return(market_return)\n",
    "        decline = max_decline_acc(w)\n",
    "        ls_decline = max_decline_add(ls_r_pnl)\n",
    "    max_decline = min(decline[:, 0])\n",
    "    max_decline = round(max_decline, 4)\n",
    "    ls_max_decline = min(ls_decline[:, 0])\n",
    "    ls_max_decline = round(ls_max_decline, 4)\n",
    "\n",
    "    max_decline_index = np.argmin(decline[:, 0])\n",
    "    b_index = decline[max_decline_index, 1]\n",
    "\n",
    "    # plt.subplot(321)\n",
    "    # sns.distplot(r, kde=True, rug=True)\n",
    "    # ax = plt.subplot(322)\n",
    "    # ax.axvline(max_decline_index, ls=\"--\", color='r')\n",
    "    # ax.axvline(b_index, ls=\"--\", color='r')\n",
    "    r = np.array(r)\n",
    "\n",
    "    sharp = (r.mean() - 0.001)/r.std()*np.sqrt(252)\n",
    "    ls_sharp = (ls_r.mean() - 0.001) / ls_r.std() * np.sqrt(252)\n",
    "    # annotate_x = int(2/3*len(w))\n",
    "    # ax.annotate('max_decline:' + str(max_decline), xy=(annotate_x, 1))\n",
    "    # ax.annotate('sharp:' + str(sharp), xy=(annotate_x, 1.5))\n",
    "    # ax.plot(market_return)\n",
    "    # ax.plot(w)\n",
    "    print(\"sharp:\", sharp)\n",
    "    print(\"max_decline\", max_decline)\n",
    "    print(\"pnl:\", w[-1])\n",
    "    print(\"sharp_ls:\", ls_sharp)\n",
    "    print(\"ls_max_decline\", ls_max_decline)\n",
    "    print(\"ls_r_pnl:\", ls_r_pnl[-1])\n",
    "    tag = list(range(0, len(w), int(len(w) / 6)))\n",
    "    tag[-1] = tag[-1] - 1\n",
    "    # ax.set_xticks(tag)\n",
    "    all_te_time = np.array(all_te_time)\n",
    "    print(all_te_time[int(b_index)], all_te_time[int(max_decline_index)])\n",
    "\n",
    "\n",
    "    # ax.set_xticklabels(all_te_time[tag], rotation=25)\n",
    "\n",
    "\n",
    "    # plt.subplot(323)\n",
    "    # f_importance_bar(importance_dic)\n",
    "    # plt.subplot(324)\n",
    "    # w = hist_count(pre, real_re, 10)\n",
    "    # w = np.array(w)\n",
    "    # w = w/w.min()\n",
    "    # sns.heatmap(w, square=True, linewidths=.5)\n",
    "    # plt.savefig(\".\\\\pic\\\\pnl_analysis.png\")\n",
    "    # plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
